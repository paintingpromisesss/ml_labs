## Лабораторная №2–3. Классификация + оптимизация гиперпараметров

- **Дата выдачи:** 07.11.2025  
- **Дедлайны:**  
  - до 21.11.2025 — максимум «5» 2  лаба;  
  - до 28.11.2025 — максимум «5» 3 лаба;  
  - до 05.12.2025 — максимум «4»;  
  - позже 05.12.2025 — максимум «3».

### Лаба 2. Бинарная классификация (Titanic)

Используем датасет [Titanic](https://www.kaggle.com/datasets/yasserh/titanic-dataset) (файл `train.csv`, целевой столбец `Survived`).

1. Подготовить данные: базовый анализ, обработка пропусков, разделение числовых и категориальных признаков.
2. Обучить `LogisticRegression` (можно Линейная регрессия, Случаный лес регрессор, Градиентный Бустинг).
3. Оценить качество: Accuracy, Precision, Recall, F1, ROC-AUC, confusion matrix, ROC-кривая.
4. Показать влияние порога (например, 0.2/0.5/0.8) на precision/recall/F1 и сделать вывод по выбору порога.
5. Сдать ноутбук с короткими комментариями и итоговой интерпретацией результатов.

### Лаба 3. Оптимизация гиперпараметров

Берём модель из ЛР2 (Titanic) или регрессию из ЛР1, если сильно хотите.

1. Зафиксировать базовую метрику (F1 или ROC-AUC для классификации; MAE для регрессии).
2. Настроить гиперпараметры через `RandomizedSearchCV` (≥15 итераций) или компактный `GridSearchCV`.
3. Сравнить метрики «до/после», вывести `best_params_`, прокомментировать, что изменилось.
4. Итоговый вывод: оставляем ли найденные настройки и почему.

ОБЯЗАТЕЛЬНО: написать буквами вывод, а то я ничего не понимаю, что изменилось и почему